{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPgGfrgQqzv/NKn60S/M24e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siu0901/AI_study/blob/main/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%A6%9D%EA%B0%95_%EC%A0%81%EC%9A%A9%ED%95%9C_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QbgUuhCyTi8m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import Dataset\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "batch_size = 64\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 40"
      ],
      "metadata": {
        "id": "0s9qmnI-xMxy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mean = [0.485, 0.456, 0.406]  # R, G, B\n",
        "train_std = [0.229, 0.224, 0.225]   # R, G, B"
      ],
      "metadata": {
        "id": "8jareMy7E3kZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.RandomCrop(224, 224),\n",
        "    A.HorizontalFlip(),\n",
        "    A.Normalize(mean=train_mean, std=train_std),\n",
        "    A.RandomBrightnessContrast(p=0.5, brightness_limit=0.8, contrast_limit=0.8),\n",
        "    ToTensorV2()\n",
        "])"
      ],
      "metadata": {
        "id": "fFe3JuwjxZRA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.CenterCrop(224, 224),\n",
        "    A.Normalize(mean=train_mean, std=train_std),\n",
        "    ToTensorV2()\n",
        "])"
      ],
      "metadata": {
        "id": "t5GEvJM9FKTL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transform():\n",
        "  def __init__(self, transform):\n",
        "    self.transform = transform\n",
        "\n",
        "  def __call__(self, img):\n",
        "    return self.transform(image=np.array(img))['image']"
      ],
      "metadata": {
        "id": "KwvVr6ZeHMOy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.STL10(root='./data', split='train', transform=Transform(train_transform), download=True)\n",
        "test_dataset = torchvision.datasets.STL10(root='./data', split='test', transform=Transform(test_transform), download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fL1ie6_JnyZ",
        "outputId": "281e2813-0169-431b-be82-dd7da84cb3cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.64G/2.64G [00:54<00:00, 48.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "Unz33x7kMmCE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16(nn.Module):\n",
        "  def __init__(self, n_class):\n",
        "    super(VGG16, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(3,64,3, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64,64,3, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2),\n",
        "\n",
        "        nn.Conv2d(64,128,3, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128,128,3, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2),\n",
        "\n",
        "        nn.Conv2d(128,256,3, padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(256,256,3, padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(256,256,3, padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2),\n",
        "\n",
        "        nn.Conv2d(256,512,3, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512,512,3, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512,512,3, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2),\n",
        "\n",
        "        nn.Conv2d(512,512,3, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512,512,3, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512,512,3, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2)\n",
        "    )\n",
        "    self.full_connected = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(7*7*512,4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(), # vgg는 보통 과적합 방지하려고 이렇게 뉴런 끔\n",
        "        nn.Linear(4096,1000),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(1000,n_class)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.full_connected(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "URdoO80YLZCm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16(n_class=10).to(device)"
      ],
      "metadata": {
        "id": "mkoiORHTL-ij"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "GksjX6wFMFD7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  running_train_loss = 0.0\n",
        "\n",
        "  for idx, (img, label) in enumerate(train_loader):\n",
        "    image = img.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(image)\n",
        "    loss = criterion(output, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_train_loss += loss.item()\n",
        "\n",
        "    if (idx+1) % 50 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{idx+1}/{len(train_loader)}], Train Loss: {running_train_loss/50:.4f}')\n",
        "        running_train_loss = 0.0\n",
        "\n",
        "  model.eval()\n",
        "  t_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for t_images, t_labels in test_loader:\n",
        "        t_images = t_images.to(device)\n",
        "        t_labels = t_labels.to(device)\n",
        "\n",
        "        t_output = model(t_images)\n",
        "        t_batch_loss = criterion(t_output, t_labels)\n",
        "        t_loss += t_batch_loss.item()\n",
        "\n",
        "        _, t_predicted = torch.max(t_output.data, 1)\n",
        "        total += t_labels.size(0)\n",
        "        correct += (t_predicted == t_labels).sum().item()\n",
        "\n",
        "    avg_test_loss = t_loss / len(test_loader)\n",
        "    test_accuracy = 100 * correct / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
        "    print('-' * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFaLI2IVMPMc",
        "outputId": "ddb00466-4298-4733-f918-0f661d02d2af"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/40], Step [50/79], Train Loss: 1.6445\n",
            "Epoch [1/40], Test Loss: 1.5780, Test Accuracy: 40.14%\n",
            "------------------------------------------------------------\n",
            "Epoch [2/40], Step [50/79], Train Loss: 1.6213\n",
            "Epoch [2/40], Test Loss: 1.5017, Test Accuracy: 43.35%\n",
            "------------------------------------------------------------\n",
            "Epoch [3/40], Step [50/79], Train Loss: 1.5896\n",
            "Epoch [3/40], Test Loss: 1.4603, Test Accuracy: 44.36%\n",
            "------------------------------------------------------------\n",
            "Epoch [4/40], Step [50/79], Train Loss: 1.5190\n",
            "Epoch [4/40], Test Loss: 1.4423, Test Accuracy: 44.92%\n",
            "------------------------------------------------------------\n",
            "Epoch [5/40], Step [50/79], Train Loss: 1.4563\n",
            "Epoch [5/40], Test Loss: 1.5204, Test Accuracy: 46.02%\n",
            "------------------------------------------------------------\n",
            "Epoch [6/40], Step [50/79], Train Loss: 1.3958\n",
            "Epoch [6/40], Test Loss: 1.3962, Test Accuracy: 48.71%\n",
            "------------------------------------------------------------\n",
            "Epoch [7/40], Step [50/79], Train Loss: 1.3777\n",
            "Epoch [7/40], Test Loss: 1.2923, Test Accuracy: 51.75%\n",
            "------------------------------------------------------------\n",
            "Epoch [8/40], Step [50/79], Train Loss: 1.3303\n",
            "Epoch [8/40], Test Loss: 1.2139, Test Accuracy: 54.49%\n",
            "------------------------------------------------------------\n",
            "Epoch [9/40], Step [50/79], Train Loss: 1.2887\n",
            "Epoch [9/40], Test Loss: 1.0945, Test Accuracy: 59.80%\n",
            "------------------------------------------------------------\n",
            "Epoch [10/40], Step [50/79], Train Loss: 1.2206\n",
            "Epoch [10/40], Test Loss: 1.0702, Test Accuracy: 60.48%\n",
            "------------------------------------------------------------\n",
            "Epoch [11/40], Step [50/79], Train Loss: 1.2134\n",
            "Epoch [11/40], Test Loss: 1.1998, Test Accuracy: 57.12%\n",
            "------------------------------------------------------------\n",
            "Epoch [12/40], Step [50/79], Train Loss: 1.1489\n",
            "Epoch [12/40], Test Loss: 1.3036, Test Accuracy: 54.00%\n",
            "------------------------------------------------------------\n",
            "Epoch [13/40], Step [50/79], Train Loss: 1.1412\n",
            "Epoch [13/40], Test Loss: 1.1360, Test Accuracy: 58.49%\n",
            "------------------------------------------------------------\n",
            "Epoch [14/40], Step [50/79], Train Loss: 1.1448\n",
            "Epoch [14/40], Test Loss: 1.1513, Test Accuracy: 57.35%\n",
            "------------------------------------------------------------\n",
            "Epoch [15/40], Step [50/79], Train Loss: 1.0885\n",
            "Epoch [15/40], Test Loss: 1.1118, Test Accuracy: 60.17%\n",
            "------------------------------------------------------------\n",
            "Epoch [16/40], Step [50/79], Train Loss: 1.0468\n",
            "Epoch [16/40], Test Loss: 1.0556, Test Accuracy: 60.81%\n",
            "------------------------------------------------------------\n",
            "Epoch [17/40], Step [50/79], Train Loss: 1.0535\n",
            "Epoch [17/40], Test Loss: 1.0544, Test Accuracy: 61.66%\n",
            "------------------------------------------------------------\n",
            "Epoch [18/40], Step [50/79], Train Loss: 1.0366\n",
            "Epoch [18/40], Test Loss: 1.0366, Test Accuracy: 62.25%\n",
            "------------------------------------------------------------\n",
            "Epoch [19/40], Step [50/79], Train Loss: 0.9803\n",
            "Epoch [19/40], Test Loss: 0.8974, Test Accuracy: 67.94%\n",
            "------------------------------------------------------------\n",
            "Epoch [20/40], Step [50/79], Train Loss: 0.9695\n",
            "Epoch [20/40], Test Loss: 0.9118, Test Accuracy: 67.40%\n",
            "------------------------------------------------------------\n",
            "Epoch [21/40], Step [50/79], Train Loss: 1.0161\n",
            "Epoch [21/40], Test Loss: 0.9566, Test Accuracy: 65.60%\n",
            "------------------------------------------------------------\n",
            "Epoch [22/40], Step [50/79], Train Loss: 0.9051\n",
            "Epoch [22/40], Test Loss: 1.1319, Test Accuracy: 60.60%\n",
            "------------------------------------------------------------\n",
            "Epoch [23/40], Step [50/79], Train Loss: 0.9198\n",
            "Epoch [23/40], Test Loss: 1.0826, Test Accuracy: 61.90%\n",
            "------------------------------------------------------------\n",
            "Epoch [24/40], Step [50/79], Train Loss: 0.8934\n",
            "Epoch [24/40], Test Loss: 0.8558, Test Accuracy: 69.89%\n",
            "------------------------------------------------------------\n",
            "Epoch [25/40], Step [50/79], Train Loss: 0.9130\n",
            "Epoch [25/40], Test Loss: 1.1541, Test Accuracy: 58.96%\n",
            "------------------------------------------------------------\n",
            "Epoch [26/40], Step [50/79], Train Loss: 0.8675\n",
            "Epoch [26/40], Test Loss: 0.9451, Test Accuracy: 67.41%\n",
            "------------------------------------------------------------\n",
            "Epoch [27/40], Step [50/79], Train Loss: 0.8547\n",
            "Epoch [27/40], Test Loss: 1.0689, Test Accuracy: 62.83%\n",
            "------------------------------------------------------------\n",
            "Epoch [28/40], Step [50/79], Train Loss: 0.8451\n",
            "Epoch [28/40], Test Loss: 0.8562, Test Accuracy: 69.79%\n",
            "------------------------------------------------------------\n",
            "Epoch [29/40], Step [50/79], Train Loss: 0.8231\n",
            "Epoch [29/40], Test Loss: 0.9728, Test Accuracy: 66.39%\n",
            "------------------------------------------------------------\n",
            "Epoch [30/40], Step [50/79], Train Loss: 0.8524\n",
            "Epoch [30/40], Test Loss: 0.7986, Test Accuracy: 71.31%\n",
            "------------------------------------------------------------\n",
            "Epoch [31/40], Step [50/79], Train Loss: 0.7857\n",
            "Epoch [31/40], Test Loss: 0.8308, Test Accuracy: 69.83%\n",
            "------------------------------------------------------------\n",
            "Epoch [32/40], Step [50/79], Train Loss: 0.7622\n",
            "Epoch [32/40], Test Loss: 0.8458, Test Accuracy: 70.30%\n",
            "------------------------------------------------------------\n",
            "Epoch [33/40], Step [50/79], Train Loss: 0.7965\n",
            "Epoch [33/40], Test Loss: 0.9080, Test Accuracy: 68.49%\n",
            "------------------------------------------------------------\n",
            "Epoch [34/40], Step [50/79], Train Loss: 0.7774\n",
            "Epoch [34/40], Test Loss: 0.9188, Test Accuracy: 69.08%\n",
            "------------------------------------------------------------\n",
            "Epoch [35/40], Step [50/79], Train Loss: 0.7195\n",
            "Epoch [35/40], Test Loss: 1.1640, Test Accuracy: 63.95%\n",
            "------------------------------------------------------------\n",
            "Epoch [36/40], Step [50/79], Train Loss: 0.7402\n",
            "Epoch [36/40], Test Loss: 0.8075, Test Accuracy: 71.72%\n",
            "------------------------------------------------------------\n",
            "Epoch [37/40], Step [50/79], Train Loss: 0.7004\n",
            "Epoch [37/40], Test Loss: 0.7469, Test Accuracy: 73.99%\n",
            "------------------------------------------------------------\n",
            "Epoch [38/40], Step [50/79], Train Loss: 0.7132\n",
            "Epoch [38/40], Test Loss: 0.7709, Test Accuracy: 73.89%\n",
            "------------------------------------------------------------\n",
            "Epoch [39/40], Step [50/79], Train Loss: 0.6722\n",
            "Epoch [39/40], Test Loss: 0.8824, Test Accuracy: 69.59%\n",
            "------------------------------------------------------------\n",
            "Epoch [40/40], Step [50/79], Train Loss: 0.7100\n",
            "Epoch [40/40], Test Loss: 0.7875, Test Accuracy: 73.17%\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "  print(f\"테스트 데이터셋 정확도: {100 * correct / total}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHkSdDHXr9-R",
        "outputId": "bc74609e-fa7e-4b1d-8061-d7db7589f768"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터셋 정확도: 73.175%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 이전에 데이터를 정제만 해서 학습 시켰을 땐 정확도가 약 68% 나왔음.\n",
        "\n",
        " 데이터를 방향 전환하고 밝기를 조절 하는 등 증강 기법을 쓰니 정확도가 73%,\n",
        " 약 5% 오른 것을 확인할 수 있었음.\n",
        "\n",
        " 결론: 데이터 증강은 필수다!"
      ],
      "metadata": {
        "id": "F3Y1JtRrsaAN"
      }
    }
  ]
}